{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blastoff_Content_Statistics_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP8mL2mnuyW2AQAJHSmTwI6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wayne122/CMPE257/blob/main/Blastoff_Content_Statistics_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OsKb1UuTygC"
      },
      "source": [
        "## Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYONuuGSkU7O",
        "outputId": "7c992f30-9068-440d-a4c7-25c8a681be89"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/Wayne122/Content_Statistics_Demo.git\n",
        "cd Content_Statistics_Demo\n",
        "pip install -r requirements.txt\n",
        "python3 -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (50.3.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (2.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r requirements.txt (line 5)) (3.4.0)\n",
            "Collecting en_core_web_lg==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py): started\n",
            "  Building wheel for en-core-web-lg (setup.py): finished with status 'done'\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=474bbe849e47faab750acfa914fe30cda44345e6bcd3739236ea75a16f9cdc64\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dm9mce6x/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Content_Statistics_Demo'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWdt1joQT2Jo"
      },
      "source": [
        "## Import module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc1GwInakqai",
        "outputId": "daeb6fd5-f2e1-49ab-bd11-4a042067aafd"
      },
      "source": [
        "# Restart runtime before running this cell\n",
        "%cd Content_Statistics_Demo/\n",
        "from Blastoff_Content_Statistics import BlastoffContentStatistics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Content_Statistics_Demo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBC9xY-lTRUy"
      },
      "source": [
        "##Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8YFFW3Z-4kN"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1sFMftHLILNfuS0kpTlsbUzWpSNs3WkeD\"})\n",
        "downloaded.GetContentFile('liar_plus_dataset.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQfX4A6S-4k2"
      },
      "source": [
        "from zipfile import ZipFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw3M_EGd-4lC"
      },
      "source": [
        "with ZipFile('liar_plus_dataset.zip', 'r') as myzip:\n",
        "    train_data = myzip.open('train2.tsv')\n",
        "    test_data = myzip.open('test2.tsv')\n",
        "    valid_data = myzip.open('val2.tsv')\n",
        "\n",
        "train_p_df = pd.read_csv(train_data, sep='\\t', header=None).drop([0], axis=1).dropna(how='all')\n",
        "test_p_df = pd.read_csv(test_data, sep='\\t', header=None).drop([0], axis=1).dropna(how='all')\n",
        "valid_p_df = pd.read_csv(valid_data, sep='\\t', header=None).drop([0], axis=1).dropna(how='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWWRQTPGTU0_"
      },
      "source": [
        "## Rename the columns\n",
        "\n",
        "as the module requires the data to have \"Statement\" and \"Label\" to train. If you just want to inference, then \"Statement\" is enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yoFc0jqQZp-"
      },
      "source": [
        "train_p_df.rename(columns={2:'Label', 3:'Statement'}, inplace=True)\n",
        "test_p_df.rename(columns={2:'Label', 3:'Statement'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbEHKIfiQ7xG"
      },
      "source": [
        "X_train = train_p_df.drop('Label', axis=1)\n",
        "y_train = train_p_df['Label']\n",
        "X_test = test_p_df.drop('Label', axis=1)\n",
        "y_test = test_p_df['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA9r9-kNTl-O"
      },
      "source": [
        "## Initialize module\n",
        "\n",
        "BlastoffContentStatistics(dpos=True, sa=True, ner=True, mpath=None)\n",
        "\n",
        "*   dpos - Detailed POS tagging\n",
        "*   as - Sentiment analysis\n",
        "*   ner - Named-entity recognition\n",
        "*   mpath - pretrained model path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UURA3L7BTvgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a7abc5-a5a0-4125-f6e9-2d985f4a0033"
      },
      "source": [
        "bcs = BlastoffContentStatistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1oTfsNgkmEBemkVfrWSjnc-K9svmL7Iak into ./bcs_encoder.zip... Done.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Loading default pretrained model.\n",
            "Downloading 1oFjoL9LWrp2-YPSJL2UhBQ1efV9LiC2n into ./content_statistic_model.pickle... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChdUlMabTokq"
      },
      "source": [
        "## Extract feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "Hnyc_lNPRCst",
        "outputId": "4fcca962-bc1a-440f-99fa-7094b23ecbbd"
      },
      "source": [
        "bcs.extract(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model not found: here.pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CC</th>\n",
              "      <th>CD</th>\n",
              "      <th>DT</th>\n",
              "      <th>EX</th>\n",
              "      <th>FW</th>\n",
              "      <th>IN</th>\n",
              "      <th>JJ</th>\n",
              "      <th>LS</th>\n",
              "      <th>MD</th>\n",
              "      <th>NN</th>\n",
              "      <th>PDT</th>\n",
              "      <th>POS</th>\n",
              "      <th>PRP</th>\n",
              "      <th>RB</th>\n",
              "      <th>RP</th>\n",
              "      <th>SYM</th>\n",
              "      <th>TO</th>\n",
              "      <th>UH</th>\n",
              "      <th>VB</th>\n",
              "      <th>WH</th>\n",
              "      <th>SA_C</th>\n",
              "      <th>SA_P</th>\n",
              "      <th>SA_NU</th>\n",
              "      <th>SA_NG</th>\n",
              "      <th>NER_pers</th>\n",
              "      <th>NER_norp</th>\n",
              "      <th>NER_fac</th>\n",
              "      <th>NER_org</th>\n",
              "      <th>NER_gpe</th>\n",
              "      <th>NER_loc</th>\n",
              "      <th>NER_prod</th>\n",
              "      <th>NER_eve</th>\n",
              "      <th>NER_woa</th>\n",
              "      <th>NER_law</th>\n",
              "      <th>NER_lang</th>\n",
              "      <th>NER_dat</th>\n",
              "      <th>NER_tim</th>\n",
              "      <th>NER_per</th>\n",
              "      <th>NER_mon</th>\n",
              "      <th>NER_quan</th>\n",
              "      <th>NER_ordi</th>\n",
              "      <th>NER_cardi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.192</td>\n",
              "      <td>0.692</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.902</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.687</td>\n",
              "      <td>0.107</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7579</td>\n",
              "      <td>0.394</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10237</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.7506</td>\n",
              "      <td>0.062</td>\n",
              "      <td>0.619</td>\n",
              "      <td>0.319</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10238</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>0.172</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10239</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5859</td>\n",
              "      <td>0.161</td>\n",
              "      <td>0.839</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10240</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10241</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6461</td>\n",
              "      <td>0.274</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10240 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       CC  CD  DT  EX  FW  ...  NER_per  NER_mon  NER_quan  NER_ordi  NER_cardi\n",
              "0       0   0   1   0   0  ...        0        0         0         1          0\n",
              "1       0   0   1   0   0  ...        0        0         0         0          0\n",
              "2       0   0   2   0   0  ...        0        0         0         0          0\n",
              "3       0   0   0   0   0  ...        0        0         0         0          0\n",
              "4       0   0   2   0   0  ...        0        0         0         0          0\n",
              "...    ..  ..  ..  ..  ..  ...      ...      ...       ...       ...        ...\n",
              "10237   0   0   1   2   0  ...        0        0         0         0          0\n",
              "10238   1   0   2   0   0  ...        0        0         0         0          0\n",
              "10239   0   0   2   0   0  ...        0        0         0         0          0\n",
              "10240   1   0   1   0   0  ...        0        0         0         0          0\n",
              "10241   0   0   2   0   1  ...        0        0         0         0          0\n",
              "\n",
              "[10240 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VHz2skOTrAq"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNx6QCn_UBu1",
        "outputId": "fe5e73e4-a761-43d1-d394-826140cada83"
      },
      "source": [
        "bcs.fit(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier = Nearest Neighbors, Score (test, accuracy) = 20.68, Training time = 0.56 seconds\n",
            "Classifier = Linear SVM, Score (test, accuracy) = 25.49, Training time = 58.24 seconds\n",
            "Classifier = RBF SVM, Score (test, accuracy) = 21.15, Training time = 119.31 seconds\n",
            "Classifier = Decision Tree, Score (test, accuracy) = 23.76, Training time = 0.03 seconds\n",
            "Classifier = Random Forest, Score (test, accuracy) = 24.55, Training time = 0.04 seconds\n",
            "Classifier = Neural Net, Score (test, accuracy) = 24.23, Training time = 14.78 seconds\n",
            "Classifier = AdaBoost, Score (test, accuracy) = 24.23, Training time = 0.74 seconds\n",
            "Classifier = Naive Bayes, Score (test, accuracy) = 8.52, Training time = 0.01 seconds\n",
            "Classifier = QDA, Score (test, accuracy) = 7.58, Training time = 0.08 seconds\n",
            "--------------------------------------------------------------------------------\n",
            "Best --> Classifier = Linear SVM, Score (test, accuracy) = 25.49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwJGRpdlTsvg"
      },
      "source": [
        "## Export the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcoEYHzSXRGX"
      },
      "source": [
        "bcs.export('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox70Nl6vTv-D"
      },
      "source": [
        "## Inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IolxCn6tcFP7"
      },
      "source": [
        "t = bcs.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dV2FOqlHe0-i",
        "outputId": "85d308e2-e229-4228-e77a-3ff4acd42ea5"
      },
      "source": [
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>half-true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>mostly-true</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1267 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label\n",
              "0           false\n",
              "1           false\n",
              "2           false\n",
              "3           false\n",
              "4       half-true\n",
              "...           ...\n",
              "1262        false\n",
              "1263        false\n",
              "1264        false\n",
              "1265        false\n",
              "1266  mostly-true\n",
              "\n",
              "[1267 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K44gKEEI78N"
      },
      "source": [
        "## Generate possibilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PObiSDwf96ZQ"
      },
      "source": [
        "prob_test = bcs.clf.predict_proba(bcs.extract(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ltLitug-Zox",
        "outputId": "8f531234-2b2f-460e-fcf7-612b0c03499f"
      },
      "source": [
        "prob_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08203474, 0.21894051, 0.14794616, 0.18739633, 0.19645298,\n",
              "        0.16722929],\n",
              "       [0.08208278, 0.21521544, 0.14954956, 0.1961557 , 0.18587003,\n",
              "        0.1711265 ],\n",
              "       [0.08246543, 0.23984141, 0.18759866, 0.20146431, 0.14983595,\n",
              "        0.13879424],\n",
              "       ...,\n",
              "       [0.08235875, 0.19065644, 0.18281095, 0.20882673, 0.18085837,\n",
              "        0.15448877],\n",
              "       [0.08235624, 0.20778048, 0.18379886, 0.20417851, 0.16247084,\n",
              "        0.15941508],\n",
              "       [0.08173541, 0.1952643 , 0.16854824, 0.20582555, 0.20163806,\n",
              "        0.14698844]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isRkNzFOB9sK",
        "outputId": "a600a615-7415-480d-baae-b80e5932ca7b"
      },
      "source": [
        "bcs.clf.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zyfezR9ltTo"
      },
      "source": [
        "# ENCODING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvKxixFwlvNM"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "encoding_dim = 16\n",
        "\n",
        "input = keras.Input(shape=(42,))\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input)\n",
        "decoded = layers.Dense(42, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input, decoded)\n",
        "\n",
        "encoder = keras.Model(input, encoded)\n",
        "\n",
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAqk9miEoCxC"
      },
      "source": [
        "p_X_train = bcs.extract(X_train)\n",
        "p_X_test = bcs.extract(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "XnIUwUgiQWpI",
        "outputId": "29942494-08a9-4a60-db3d-46f9c592e8d8"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>Statement</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11972.json</td>\n",
              "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
              "      <td>immigration</td>\n",
              "      <td>rick-perry</td>\n",
              "      <td>Governor</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>Radio interview</td>\n",
              "      <td>Meantime, engineering experts agree the wall w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11685.json</td>\n",
              "      <td>Wisconsin is on pace to double the number of l...</td>\n",
              "      <td>jobs</td>\n",
              "      <td>katrina-shankland</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>democrat</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a news conference</td>\n",
              "      <td>She cited layoff notices received by the state...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11096.json</td>\n",
              "      <td>Says John McCain has done nothing to help the ...</td>\n",
              "      <td>military,veterans,voting-record</td>\n",
              "      <td>donald-trump</td>\n",
              "      <td>President-Elect</td>\n",
              "      <td>New York</td>\n",
              "      <td>republican</td>\n",
              "      <td>63</td>\n",
              "      <td>114</td>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "      <td>61</td>\n",
              "      <td>comments on ABC's This Week.</td>\n",
              "      <td>Trump said that McCain \"has done nothing to he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5209.json</td>\n",
              "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
              "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
              "      <td>rob-cornilles</td>\n",
              "      <td>consultant</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>republican</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a radio show</td>\n",
              "      <td>But spending still goes up. In addition, many ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9524.json</td>\n",
              "      <td>When asked by a reporter whether hes at the ce...</td>\n",
              "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
              "      <td>state-democratic-party-wisconsin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>democrat</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>a web video</td>\n",
              "      <td>Our rating A Democratic Party web video making...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>7334.json</td>\n",
              "      <td>Says his budget provides the highest state fun...</td>\n",
              "      <td>education</td>\n",
              "      <td>rick-scott</td>\n",
              "      <td>Governor</td>\n",
              "      <td>Florida</td>\n",
              "      <td>republican</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>38</td>\n",
              "      <td>34</td>\n",
              "      <td>7</td>\n",
              "      <td>a news conference</td>\n",
              "      <td>LeMieux didn't compare Rubio and Obama on an i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>9788.json</td>\n",
              "      <td>Ive been here almost every day.</td>\n",
              "      <td>civil-rights,crime,criminal-justice</td>\n",
              "      <td>jay-nixon</td>\n",
              "      <td>Governor</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>democrat</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>on ABC's \"This Week\"</td>\n",
              "      <td>After making his pledge, Obama said the budget...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>10710.json</td>\n",
              "      <td>In the early 1980s, Sen. Edward Kennedy secret...</td>\n",
              "      <td>bipartisanship,congress,foreign-policy,history</td>\n",
              "      <td>mackubin-thomas-owens</td>\n",
              "      <td>senior fellow, Foreign Policy Research Institute</td>\n",
              "      <td>Rhode Island</td>\n",
              "      <td>columnist</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a commentary in The Providence Journal</td>\n",
              "      <td>Former President Clinton said government got t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>3186.json</td>\n",
              "      <td>Says an EPA permit languished under Strickland...</td>\n",
              "      <td>environment,government-efficiency</td>\n",
              "      <td>john-kasich</td>\n",
              "      <td>Governor of Ohio as of Jan. 10, 2011</td>\n",
              "      <td>Ohio</td>\n",
              "      <td>republican</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>a news conference</td>\n",
              "      <td>Points of Light has a unique mission carved ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>6743.json</td>\n",
              "      <td>Says the governor is going around the state ta...</td>\n",
              "      <td>state-budget,state-finances,taxes</td>\n",
              "      <td>john-burzichelli</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>democrat</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>an interview with NJToday</td>\n",
              "      <td>In reality, the Affordable Care Act calls for ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1267 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              1   ...                                                 15\n",
              "0     11972.json  ...  Meantime, engineering experts agree the wall w...\n",
              "1     11685.json  ...  She cited layoff notices received by the state...\n",
              "2     11096.json  ...  Trump said that McCain \"has done nothing to he...\n",
              "3      5209.json  ...  But spending still goes up. In addition, many ...\n",
              "4      9524.json  ...  Our rating A Democratic Party web video making...\n",
              "...          ...  ...                                                ...\n",
              "1262   7334.json  ...  LeMieux didn't compare Rubio and Obama on an i...\n",
              "1263   9788.json  ...  After making his pledge, Obama said the budget...\n",
              "1264  10710.json  ...  Former President Clinton said government got t...\n",
              "1265   3186.json  ...  Points of Light has a unique mission carved ou...\n",
              "1266   6743.json  ...  In reality, the Affordable Care Act calls for ...\n",
              "\n",
              "[1267 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y57yd1Qmbld",
        "outputId": "6b36ba5f-3247-484b-c8a8-0f6c8cf4bb1b"
      },
      "source": [
        "autoencoder.fit(p_X_train, p_X_train,\n",
        "                epochs=85,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(p_X_test, p_X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/85\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 2.2492 - accuracy: 0.0000e+00 - val_loss: 2.9188 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.9745 - accuracy: 0.0312 - val_loss: 2.6597 - val_accuracy: 0.1507\n",
            "Epoch 3/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.8047 - accuracy: 0.3887 - val_loss: 2.5724 - val_accuracy: 0.5549\n",
            "Epoch 4/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7597 - accuracy: 0.6249 - val_loss: 2.5540 - val_accuracy: 0.6717\n",
            "Epoch 5/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7482 - accuracy: 0.6974 - val_loss: 2.5461 - val_accuracy: 0.7001\n",
            "Epoch 6/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7417 - accuracy: 0.7250 - val_loss: 2.5399 - val_accuracy: 0.7309\n",
            "Epoch 7/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7363 - accuracy: 0.7274 - val_loss: 2.5348 - val_accuracy: 0.7395\n",
            "Epoch 8/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7317 - accuracy: 0.7295 - val_loss: 2.5301 - val_accuracy: 0.7364\n",
            "Epoch 9/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7274 - accuracy: 0.7237 - val_loss: 2.5255 - val_accuracy: 0.7238\n",
            "Epoch 10/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7231 - accuracy: 0.6980 - val_loss: 2.5207 - val_accuracy: 0.6654\n",
            "Epoch 11/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7186 - accuracy: 0.6527 - val_loss: 2.5164 - val_accuracy: 0.6267\n",
            "Epoch 12/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7145 - accuracy: 0.6318 - val_loss: 2.5122 - val_accuracy: 0.6117\n",
            "Epoch 13/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7108 - accuracy: 0.6133 - val_loss: 2.5086 - val_accuracy: 0.6109\n",
            "Epoch 14/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7073 - accuracy: 0.6013 - val_loss: 2.5047 - val_accuracy: 0.5856\n",
            "Epoch 15/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.7035 - accuracy: 0.5703 - val_loss: 2.5005 - val_accuracy: 0.5549\n",
            "Epoch 16/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6996 - accuracy: 0.5279 - val_loss: 2.4966 - val_accuracy: 0.5028\n",
            "Epoch 17/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6961 - accuracy: 0.4983 - val_loss: 2.4932 - val_accuracy: 0.4972\n",
            "Epoch 18/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6929 - accuracy: 0.4963 - val_loss: 2.4902 - val_accuracy: 0.4901\n",
            "Epoch 19/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6901 - accuracy: 0.4997 - val_loss: 2.4876 - val_accuracy: 0.5020\n",
            "Epoch 20/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6877 - accuracy: 0.5092 - val_loss: 2.4854 - val_accuracy: 0.5154\n",
            "Epoch 21/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6855 - accuracy: 0.5239 - val_loss: 2.4836 - val_accuracy: 0.5264\n",
            "Epoch 22/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6836 - accuracy: 0.5362 - val_loss: 2.4815 - val_accuracy: 0.5391\n",
            "Epoch 23/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6818 - accuracy: 0.5511 - val_loss: 2.4798 - val_accuracy: 0.5462\n",
            "Epoch 24/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6801 - accuracy: 0.5587 - val_loss: 2.4780 - val_accuracy: 0.5556\n",
            "Epoch 25/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6786 - accuracy: 0.5716 - val_loss: 2.4766 - val_accuracy: 0.5706\n",
            "Epoch 26/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6771 - accuracy: 0.5790 - val_loss: 2.4752 - val_accuracy: 0.5738\n",
            "Epoch 27/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6757 - accuracy: 0.5854 - val_loss: 2.4738 - val_accuracy: 0.5699\n",
            "Epoch 28/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.5948 - val_loss: 2.4727 - val_accuracy: 0.5833\n",
            "Epoch 29/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6732 - accuracy: 0.6013 - val_loss: 2.4713 - val_accuracy: 0.5848\n",
            "Epoch 30/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6720 - accuracy: 0.6056 - val_loss: 2.4700 - val_accuracy: 0.5904\n",
            "Epoch 31/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6709 - accuracy: 0.6117 - val_loss: 2.4690 - val_accuracy: 0.5943\n",
            "Epoch 32/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6699 - accuracy: 0.6162 - val_loss: 2.4680 - val_accuracy: 0.5967\n",
            "Epoch 33/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6689 - accuracy: 0.6190 - val_loss: 2.4670 - val_accuracy: 0.6085\n",
            "Epoch 34/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6680 - accuracy: 0.6229 - val_loss: 2.4661 - val_accuracy: 0.6062\n",
            "Epoch 35/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6671 - accuracy: 0.6258 - val_loss: 2.4653 - val_accuracy: 0.6093\n",
            "Epoch 36/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6663 - accuracy: 0.6287 - val_loss: 2.4645 - val_accuracy: 0.6156\n",
            "Epoch 37/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6655 - accuracy: 0.6302 - val_loss: 2.4637 - val_accuracy: 0.6188\n",
            "Epoch 38/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6648 - accuracy: 0.6332 - val_loss: 2.4630 - val_accuracy: 0.6259\n",
            "Epoch 39/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6641 - accuracy: 0.6361 - val_loss: 2.4623 - val_accuracy: 0.6243\n",
            "Epoch 40/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6634 - accuracy: 0.6376 - val_loss: 2.4616 - val_accuracy: 0.6283\n",
            "Epoch 41/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6628 - accuracy: 0.6405 - val_loss: 2.4609 - val_accuracy: 0.6338\n",
            "Epoch 42/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6621 - accuracy: 0.6426 - val_loss: 2.4603 - val_accuracy: 0.6377\n",
            "Epoch 43/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6616 - accuracy: 0.6443 - val_loss: 2.4597 - val_accuracy: 0.6425\n",
            "Epoch 44/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.6460 - val_loss: 2.4591 - val_accuracy: 0.6464\n",
            "Epoch 45/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.6483 - val_loss: 2.4586 - val_accuracy: 0.6440\n",
            "Epoch 46/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6599 - accuracy: 0.6501 - val_loss: 2.4580 - val_accuracy: 0.6472\n",
            "Epoch 47/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6593 - accuracy: 0.6504 - val_loss: 2.4575 - val_accuracy: 0.6496\n",
            "Epoch 48/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6588 - accuracy: 0.6507 - val_loss: 2.4570 - val_accuracy: 0.6567\n",
            "Epoch 49/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6584 - accuracy: 0.6544 - val_loss: 2.4564 - val_accuracy: 0.6543\n",
            "Epoch 50/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6578 - accuracy: 0.6554 - val_loss: 2.4559 - val_accuracy: 0.6606\n",
            "Epoch 51/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6575 - accuracy: 0.6615 - val_loss: 2.4553 - val_accuracy: 0.6677\n",
            "Epoch 52/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6568 - accuracy: 0.6612 - val_loss: 2.4546 - val_accuracy: 0.6764\n",
            "Epoch 53/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6563 - accuracy: 0.6623 - val_loss: 2.4541 - val_accuracy: 0.6803\n",
            "Epoch 54/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6558 - accuracy: 0.6641 - val_loss: 2.4537 - val_accuracy: 0.6803\n",
            "Epoch 55/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6554 - accuracy: 0.6644 - val_loss: 2.4532 - val_accuracy: 0.6811\n",
            "Epoch 56/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6549 - accuracy: 0.6656 - val_loss: 2.4528 - val_accuracy: 0.6851\n",
            "Epoch 57/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6545 - accuracy: 0.6659 - val_loss: 2.4523 - val_accuracy: 0.6819\n",
            "Epoch 58/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6541 - accuracy: 0.6679 - val_loss: 2.4519 - val_accuracy: 0.6867\n",
            "Epoch 59/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6536 - accuracy: 0.6686 - val_loss: 2.4515 - val_accuracy: 0.6882\n",
            "Epoch 60/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6532 - accuracy: 0.6698 - val_loss: 2.4511 - val_accuracy: 0.6843\n",
            "Epoch 61/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6528 - accuracy: 0.6712 - val_loss: 2.4507 - val_accuracy: 0.6890\n",
            "Epoch 62/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6524 - accuracy: 0.6729 - val_loss: 2.4503 - val_accuracy: 0.6898\n",
            "Epoch 63/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6521 - accuracy: 0.6748 - val_loss: 2.4500 - val_accuracy: 0.6938\n",
            "Epoch 64/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6517 - accuracy: 0.6761 - val_loss: 2.4496 - val_accuracy: 0.6938\n",
            "Epoch 65/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6513 - accuracy: 0.6790 - val_loss: 2.4492 - val_accuracy: 0.7009\n",
            "Epoch 66/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6509 - accuracy: 0.6808 - val_loss: 2.4489 - val_accuracy: 0.6985\n",
            "Epoch 67/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6506 - accuracy: 0.6824 - val_loss: 2.4485 - val_accuracy: 0.7001\n",
            "Epoch 68/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6502 - accuracy: 0.6866 - val_loss: 2.4481 - val_accuracy: 0.7024\n",
            "Epoch 69/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6499 - accuracy: 0.6892 - val_loss: 2.4478 - val_accuracy: 0.7040\n",
            "Epoch 70/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6495 - accuracy: 0.6904 - val_loss: 2.4476 - val_accuracy: 0.7017\n",
            "Epoch 71/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6492 - accuracy: 0.6929 - val_loss: 2.4473 - val_accuracy: 0.7032\n",
            "Epoch 72/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6489 - accuracy: 0.6943 - val_loss: 2.4470 - val_accuracy: 0.7048\n",
            "Epoch 73/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6487 - accuracy: 0.6963 - val_loss: 2.4467 - val_accuracy: 0.7056\n",
            "Epoch 74/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6484 - accuracy: 0.6975 - val_loss: 2.4465 - val_accuracy: 0.7064\n",
            "Epoch 75/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6481 - accuracy: 0.6976 - val_loss: 2.4463 - val_accuracy: 0.7072\n",
            "Epoch 76/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6479 - accuracy: 0.6994 - val_loss: 2.4461 - val_accuracy: 0.7072\n",
            "Epoch 77/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6476 - accuracy: 0.6993 - val_loss: 2.4458 - val_accuracy: 0.7056\n",
            "Epoch 78/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6474 - accuracy: 0.7005 - val_loss: 2.4456 - val_accuracy: 0.7032\n",
            "Epoch 79/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6472 - accuracy: 0.6996 - val_loss: 2.4454 - val_accuracy: 0.7072\n",
            "Epoch 80/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6469 - accuracy: 0.6997 - val_loss: 2.4452 - val_accuracy: 0.7017\n",
            "Epoch 81/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6467 - accuracy: 0.6992 - val_loss: 2.4450 - val_accuracy: 0.7056\n",
            "Epoch 82/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6465 - accuracy: 0.6987 - val_loss: 2.4448 - val_accuracy: 0.7017\n",
            "Epoch 83/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6464 - accuracy: 0.6994 - val_loss: 2.4446 - val_accuracy: 0.7040\n",
            "Epoch 84/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6462 - accuracy: 0.6990 - val_loss: 2.4445 - val_accuracy: 0.7064\n",
            "Epoch 85/85\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.6460 - accuracy: 0.7003 - val_loss: 2.4443 - val_accuracy: 0.7072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd320e09cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v296ZYvx1dtS"
      },
      "source": [
        "## Test encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Ilx5mxX4S-a2",
        "outputId": "e0033bc9-c096-4c00-e1f4-45619919eef9"
      },
      "source": [
        "p_X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CC</th>\n",
              "      <th>CD</th>\n",
              "      <th>DT</th>\n",
              "      <th>EX</th>\n",
              "      <th>FW</th>\n",
              "      <th>IN</th>\n",
              "      <th>JJ</th>\n",
              "      <th>LS</th>\n",
              "      <th>MD</th>\n",
              "      <th>NN</th>\n",
              "      <th>PDT</th>\n",
              "      <th>POS</th>\n",
              "      <th>PRP</th>\n",
              "      <th>RB</th>\n",
              "      <th>RP</th>\n",
              "      <th>SYM</th>\n",
              "      <th>TO</th>\n",
              "      <th>UH</th>\n",
              "      <th>VB</th>\n",
              "      <th>WH</th>\n",
              "      <th>SA_C</th>\n",
              "      <th>SA_P</th>\n",
              "      <th>SA_NU</th>\n",
              "      <th>SA_NG</th>\n",
              "      <th>NER_pers</th>\n",
              "      <th>NER_norp</th>\n",
              "      <th>NER_fac</th>\n",
              "      <th>NER_org</th>\n",
              "      <th>NER_gpe</th>\n",
              "      <th>NER_loc</th>\n",
              "      <th>NER_prod</th>\n",
              "      <th>NER_eve</th>\n",
              "      <th>NER_woa</th>\n",
              "      <th>NER_law</th>\n",
              "      <th>NER_lang</th>\n",
              "      <th>NER_dat</th>\n",
              "      <th>NER_tim</th>\n",
              "      <th>NER_per</th>\n",
              "      <th>NER_mon</th>\n",
              "      <th>NER_quan</th>\n",
              "      <th>NER_ordi</th>\n",
              "      <th>NER_cardi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0772</td>\n",
              "      <td>0.106</td>\n",
              "      <td>0.894</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.3089</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.799</td>\n",
              "      <td>0.201</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3400</td>\n",
              "      <td>0.288</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.135</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.5994</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.659</td>\n",
              "      <td>0.242</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>0.119</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3374</td>\n",
              "      <td>0.142</td>\n",
              "      <td>0.791</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1267 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CC  CD  DT  EX  FW  ...  NER_per  NER_mon  NER_quan  NER_ordi  NER_cardi\n",
              "0      0   0   2   0   0  ...        0        0         0         0          0\n",
              "1      0   0   2   0   0  ...        0        0         0         0          0\n",
              "2      0   0   1   0   0  ...        0        0         0         0          0\n",
              "3      0   0   1   0   0  ...        0        0         0         0          0\n",
              "4      0   0   3   0   0  ...        0        0         0         0          0\n",
              "...   ..  ..  ..  ..  ..  ...      ...      ...       ...       ...        ...\n",
              "1262   0   0   1   0   0  ...        0        0         0         0          0\n",
              "1263   0   0   1   0   0  ...        0        0         0         0          0\n",
              "1264   0   1   2   0   0  ...        0        0         0         0          0\n",
              "1265   1   1   1   0   0  ...        0        0         0         0          0\n",
              "1266   1   0   3   0   0  ...        0        0         0         0          0\n",
              "\n",
              "[1267 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8vGHypBuG7w",
        "outputId": "346145dd-3a36-43c8-f84b-43988f9444a0"
      },
      "source": [
        "encoder.predict(p_X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6610156, 4.9395194, 2.9832437, ..., 2.9553337, 4.8539658,\n",
              "        2.2865112],\n",
              "       [3.7399297, 3.4288416, 0.7154356, ..., 2.840631 , 4.7466674,\n",
              "        2.065889 ],\n",
              "       [3.1967797, 3.2853818, 1.986229 , ..., 4.155172 , 3.043211 ,\n",
              "        2.496645 ],\n",
              "       ...,\n",
              "       [5.5865054, 1.2594497, 7.5452027, ..., 3.5307326, 8.895622 ,\n",
              "        4.6662755],\n",
              "       [5.7518034, 2.6379714, 4.580003 , ..., 4.2373204, 1.4538329,\n",
              "        5.756905 ],\n",
              "       [6.453235 , 3.27547  , 5.0840454, ..., 4.417034 , 5.9056306,\n",
              "        5.0748243]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-N7A-O61cLp"
      },
      "source": [
        "## Save encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VouqUwGvYPf",
        "outputId": "2c0c588e-7577-434a-f195-92aa483240c4"
      },
      "source": [
        "encoder.save('/content/bcs_encoder')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/bcs_encoder/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pw92cck1W9H"
      },
      "source": [
        "## Load and test encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3UkG1uvv1O_",
        "outputId": "3be96cbf-d48a-460a-adc9-f1a4aa9cd4b1"
      },
      "source": [
        "encoder_reloaded = keras.models.load_model('/content/bcs_encoder')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxdPskC1wQad",
        "outputId": "3a36b10e-6a86-4aba-cf0a-975c7d369f59"
      },
      "source": [
        "encoder_reloaded.predict(p_X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.840651 ,  4.7654595, 14.986643 , ..., 12.210411 , 14.633874 ,\n",
              "         9.988829 ],\n",
              "       [15.701    ,  4.0937634, 12.443446 , ...,  9.242275 ,  5.9453783,\n",
              "        16.075352 ],\n",
              "       [ 9.099114 ,  9.711052 , 12.322859 , ...,  9.27873  ,  7.040361 ,\n",
              "        10.212723 ],\n",
              "       ...,\n",
              "       [14.428387 , 15.557939 , 21.380577 , ..., 19.371414 , 10.255583 ,\n",
              "        13.62308  ],\n",
              "       [14.294861 , 11.599106 ,  9.861072 , ..., 20.696312 , 16.158012 ,\n",
              "        11.004672 ],\n",
              "       [10.039318 , 23.554214 , 16.21031  , ...,  6.7429595, 16.444586 ,\n",
              "        15.835458 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLyHIECm1UjR"
      },
      "source": [
        "## Zip encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl8Z9D93xvnv"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihqYY6wFxy_6",
        "outputId": "88b1b194-ce87-4c2c-9017-298548218afb"
      },
      "source": [
        "%cd /content/\n",
        "zipf = zipfile.ZipFile('bcs_encoder.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "zipdir('bcs_encoder/', zipf)\n",
        "zipf.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82s9tHK71P5b"
      },
      "source": [
        "## Unzip encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejtEZfT0w6t0"
      },
      "source": [
        "archive = ZipFile('bcs_encoder.zip')\n",
        "\n",
        "for file in archive.namelist():\n",
        "    archive.extract(file, '/content/test/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZRuV4sF1Lsq"
      },
      "source": [
        "## Test encoder in the module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw4VVx8Q4DnG",
        "outputId": "c6e4cf1d-91c6-455c-d2e0-3f23a915210a"
      },
      "source": [
        "bcs.encode(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.840651 ,  4.7654595, 14.986643 , ..., 12.210411 , 14.633874 ,\n",
              "         9.988829 ],\n",
              "       [15.701    ,  4.0937634, 12.443446 , ...,  9.242275 ,  5.9453783,\n",
              "        16.075352 ],\n",
              "       [ 9.099114 ,  9.711052 , 12.322859 , ...,  9.27873  ,  7.040361 ,\n",
              "        10.212723 ],\n",
              "       ...,\n",
              "       [14.428387 , 15.557939 , 21.380577 , ..., 19.371414 , 10.255583 ,\n",
              "        13.62308  ],\n",
              "       [14.294861 , 11.599106 ,  9.861072 , ..., 20.696312 , 16.158012 ,\n",
              "        11.004672 ],\n",
              "       [10.039318 , 23.55421  , 16.21031  , ...,  6.74296  , 16.444586 ,\n",
              "        15.835457 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}